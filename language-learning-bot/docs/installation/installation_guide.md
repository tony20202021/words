# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ (–û–ë–ù–û–í–õ–ï–ù–û —Å AI)

## üî• –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### Hardware Requirements –¥–ª—è AI:

#### **Minimum (12GB GPU):**
```
GPU: RTX 3080, RTX 4070 Ti, A4000
RAM: 32GB System RAM
Storage: 100GB+ –¥–ª—è AI –º–æ–¥–µ–ª–µ–π
CUDA: 11.8+
```

#### **Recommended (24GB+ GPU):**
```
GPU: RTX 3090, RTX 4090, A5000, A6000
RAM: 64GB System RAM
Storage: 500GB+ NVMe SSD
CUDA: 11.8+
```

#### **Optimal (80GB+ GPU):**
```
GPU: A100, H100
RAM: 128GB+ System RAM
Storage: 1TB+ NVMe SSD
CUDA: 11.8+
```

### Software Requirements:
- Python 3.8+
- MongoDB 5.0+
- CUDA 11.8+
- Git LFS
- FFmpeg

## –ë—ã—Å—Ç—Ä–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
```bash
git clone https://github.com/username/language-learning-bot.git
cd language-learning-bot

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Git LFS –¥–ª—è AI –º–æ–¥–µ–ª–µ–π
git lfs install
```

### 2. üî• –ù–∞—Å—Ç—Ä–æ–π–∫–∞ AI –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ AI –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
conda env create -f environment_gpu.yml
conda activate amikhalev_writing_images_service

# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name()}')"
```

### 3. üî• –£—Å—Ç–∞–Ω–æ–≤–∫–∞ AI –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
```bash
# AI –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è GPU
pip install -r writing_service/requirements_gpu.txt

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö AI –±–∏–±–ª–∏–æ—Ç–µ–∫
python -c "import diffusers, transformers, xformers; print('AI libraries OK')"
```

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
```bash
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env –∏ –¥–æ–±–∞–≤—å—Ç–µ TELEGRAM_BOT_TOKEN
```

### 5. üî• –°–æ–∑–¥–∞–Ω–∏–µ AI –∫—ç—à –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ cache –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è AI –º–æ–¥–µ–ª–µ–π
mkdir -p writing_service/cache/{huggingface,transformers,torch,pytorch_kernel_cache}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
export HF_HOME="./writing_service/cache/huggingface"
export TORCH_HOME="./writing_service/cache/torch"
export TRANSFORMERS_CACHE="./writing_service/cache/transformers"
```

### 6. –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–æ–≤
```bash
./start_1_db.sh          # MongoDB
./start_2_backend.sh     # Backend API
./start_4_writing_service.sh # üî• AI —Å–µ—Ä–≤–∏—Å
./start_3_frontend.sh    # Telegram –±–æ—Ç
```

## –î–µ—Ç–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### üî• AI Environment Setup

#### **GPU Validation:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA –¥—Ä–∞–π–≤–µ—Ä–æ–≤
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
nvcc --version

# –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch —Å CUDA
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA version: {torch.version.cuda}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name()}')
    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')
"
```

#### **AI Dependencies Installation:**
```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ AI frameworks
pip install torch>=2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# HuggingFace ecosystem
pip install diffusers>=0.25.0 transformers>=4.39.0 accelerate>=0.24.0

# Optimization libraries
pip install xformers>=0.0.22
pip install controlnet-aux>=0.0.10

# Monitoring
pip install pynvml>=11.5.0 gpustat>=1.1.0
```

### MongoDB Setup
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ MongoDB
sudo apt-get install -y mongodb

# –ò–ª–∏ —á–µ—Ä–µ–∑ Docker
docker run -d -p 27017:27017 --name mongodb mongo:5.0
```

### üî• Writing Service Configuration

#### **AI Generation Config** (`writing_service/conf/config/ai_generation.yaml`):
```yaml
ai_generation:
  enabled: true
  
  models:
    base_model: "stabilityai/stable-diffusion-xl-base-1.0"
    controlnet_models:
      union: "xinsir/controlnet-union-sdxl-1.0"
  
  generation:
    num_inference_steps: 30
    guidance_scale: 7.5
    width: 1024
    height: 1024
    batch_size: 1  # –£–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è 80GB GPU
  
  gpu:
    device: "cuda"
    memory_efficient: true    # false –¥–ª—è 80GB GPU
    enable_attention_slicing: true  # false –¥–ª—è 80GB GPU
    max_batch_size: 2         # 4-8 –¥–ª—è 80GB GPU
```

## –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫

### 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
```bash
python scripts/init_db.py
python scripts/seed_data.py
```

### 2. üî• –ü—Ä–æ–≤–µ—Ä–∫–∞ AI —Å–µ—Ä–≤–∏—Å–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è AI
curl http://localhost:8600/health

# –î–µ—Ç–∞–ª—å–Ω–∞—è AI –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
curl http://localhost:8600/health/detailed

# –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å AI –º–æ–¥–µ–ª–µ–π
curl http://localhost:8600/health/ready
```

### 3. üî• –¢–µ—Å—Ç–æ–≤–∞—è AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
```bash
curl -X POST http://localhost:8600/api/writing/generate-writing-image \
  -H "Content-Type: application/json" \
  -d '{
    "word": "ÊµãËØï",
    "translation": "test",
    "width": 512,
    "height": 512
  }'
```

### 4. –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç
# –û—Ç–ø—Ä–∞–≤—å—Ç–µ /start –±–æ—Ç—É –≤ Telegram
```

## üî• AI Model Management

### Automatic Model Download
–ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ:
- Stable Diffusion XL: ~7GB
- Union ControlNet: ~2.5GB
- VAE & Scheduler: ~1GB

### Manual Model Download (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
```bash
python scripts/ai_model_downloader.py --model sdxl-base
python scripts/ai_model_downloader.py --model union-controlnet
```

### Model Cache Locations
```bash
writing_service/cache/
‚îú‚îÄ‚îÄ huggingface/               # HuggingFace –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ hub/
‚îÇ       ‚îú‚îÄ‚îÄ models--stabilityai--stable-diffusion-xl-base-1.0/
‚îÇ       ‚îî‚îÄ‚îÄ models--xinsir--controlnet-union-sdxl-1.0/
‚îú‚îÄ‚îÄ torch/                     # PyTorch cache
‚îî‚îÄ‚îÄ pytorch_kernel_cache/      # Compiled CUDA kernels
```

## Troubleshooting

### üî• AI Issues

#### **CUDA Out of Memory:**
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å batch size
echo "generation.batch_size: 1" >> writing_service/conf/config/ai_generation.yaml

# –í–∫–ª—é—á–∏—Ç—å memory optimizations
echo "gpu.memory_efficient: true" >> writing_service/conf/config/ai_generation.yaml
```

#### **Model Loading Failures:**
```bash
# –û—á–∏—Å—Ç–∏—Ç—å cache
rm -rf writing_service/cache/huggingface/*

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ç–µ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
curl -I https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0
```

#### **Slow Generation:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU utilization
nvidia-smi -l 1

# –í–∫–ª—é—á–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
echo "gpu.use_torch_compile: true" >> writing_service/conf/config/ai_generation.yaml
```

### Common Issues

#### **Dependencies:**
```bash
# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤
pip install --force-reinstall xformers
pip install --upgrade diffusers transformers
```

#### **Permissions:**
```bash
# –ü—Ä–∞–≤–∞ –Ω–∞ cache –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
chmod -R 755 writing_service/cache/
```

#### **Port Conflicts:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–Ω—è—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤
lsof -i :8600  # Writing Service
lsof -i :8500  # Backend
lsof -i :27017 # MongoDB
```

## Performance Optimization

### üî• GPU Optimization

#### **Memory Settings:**
```bash
# –î–ª—è 12GB GPU
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# –î–ª—è 24GB+ GPU  
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

#### **CUDA Settings:**
```bash
export CUDA_VISIBLE_DEVICES=0
export TOKENIZERS_PARALLELISM=false
```

### **Monitoring Setup:**
```bash
# Continuous GPU monitoring
watch -n 1 nvidia-smi

# AI service monitoring
tail -f writing_service/logs/writing_service.log | grep "AI"
```

## Development Setup

### Auto-reload Development
```bash
# Frontend auto-reload
./start_3_frontend_auto_reload.sh

# Backend auto-reload (built-in FastAPI)
# Writing Service auto-reload (built-in FastAPI)
```

### Testing
```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã
./run_tests.sh

# AI —Ç–µ—Å—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ
pytest writing_service/tests/test_ai/ -v

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ AI —Ç–µ—Å—Ç—ã
pytest writing_service/tests/integration/ -v
```

---

**üéØ –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏:**

1. ‚úÖ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ AI health checks
2. ‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
3. ‚úÖ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU
4. ‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç–µ Telegram –±–æ—Ç–∞
5. ‚úÖ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã —Ä–∞–±–æ—Ç–∞—é—Ç

**üî• Ready –¥–ª—è production AI generation!**
