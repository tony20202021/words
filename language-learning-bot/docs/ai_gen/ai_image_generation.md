# AI Image Generation - Ð ÐµÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹

## ÐžÐ±Ð·Ð¾Ñ€ AI ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹

Writing Service Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ **Ñ€ÐµÐ°Ð»ÑŒÐ½ÑƒÑŽ AI ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ** Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ ÑÐ»Ð¾Ð², Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½ÑƒÑŽ Ð½Ð° **Stable Diffusion XL** Ñ **Union ControlNet**.

### ðŸŽ¯ ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸
- **Union ControlNet Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ** - ÐµÐ´Ð¸Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²Ð¼ÐµÑÑ‚Ð¾ 4 Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ…
- **GPU Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ** - Ð°Ð²Ñ‚Ð¾Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð¾Ð´ Ð¶ÐµÐ»ÐµÐ·Ð¾ (12GB-80GB)
- **Production ready** - health monitoring, error handling

### ðŸ—ï¸ Ð¢ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÑ‚ÐµÐº
```
AI Models:
â”œâ”€â”€ Stable Diffusion XL Base 1.0        # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
â”œâ”€â”€ Union ControlNet SDXL 1.0            # ControlNet Ð¼Ð¾Ð´ÐµÐ»ÑŒ
â””â”€â”€ Optimized VAE & Scheduler            # ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸

AI Frameworks:  
â”œâ”€â”€ Diffusers >= 0.25.0                  # HuggingFace
â”œâ”€â”€ PyTorch >= 2.1.0                     # ML framework
â”œâ”€â”€ XFormers >= 0.0.22                   # Optimization
â””â”€â”€ CUDA 11.8+                           # GPU support
```

## ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° AI ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²

### ðŸŽ¯ AI Pipeline:
```
Character â†’ Preprocessing â†’ Multi-Conditioning â†’ Prompt â†’ Union ControlNet â†’ SDXL â†’ Result
```

### ðŸ—ï¸ ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹:

#### 1. **AIImageGenerator** (`ai_image_generator.py`)
ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ orchestrator AI pipeline:
```python
class AIImageGenerator:
    async def generate_character_image(
        self, character: str, translation: str = ""
    ) -> AIGenerationResult
```

#### 2. **MultiControlNetPipeline** (`multi_controlnet_pipeline.py`) 
Union ControlNet integration:
```python
class MultiControlNetPipeline:
    async def generate(
        self, prompt: str, control_images: Dict
    ) -> Image.Image
```

#### 3. **Conditioning Generators**
- **CannyConditioning** - edge detection
- **DepthConditioning** - depth estimation  
- **SegmentationConditioning** - image segmentation
- **ScribbleConditioning** - artistic sketches

#### 4. **PromptBuilder** (`prompt_builder.py`)
Intelligent prompt engineering:
```python
class PromptBuilder:
    async def build_prompt(
        self, character: str, style: str = "comic"
    ) -> PromptResult
```

#### 5. **ModelLoader** (`model_loader.py`)
AI model management:
```python
class ModelLoader:
    async def load_stable_diffusion_xl(self, model_name: str)
    async def load_controlnet_models(self, model_configs: Dict)
```

#### 6. **GPUManager** (`gpu_manager.py`)
GPU resource management:
```python
class GPUManager:
    def get_gpu_status(self) -> GPUStatus
    def optimize_pipeline(self, pipeline) -> Dict
```

## Multi-ControlNet Pipeline

### ðŸŽ›ï¸ Union ControlNet Architecture
Union ControlNet Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ **4 Ñ‚Ð¸Ð¿Ð° conditioning** Ð² ÐµÐ´Ð¸Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸:

```python
# Ð¢Ð¸Ð¿Ñ‹ conditioning Ð² Union ControlNet
control_type_mapping = {
    "depth": 1,       # Depth estimation
    "canny": 3,       # Edge detection  
    "segment": 5,     # Segmentation
    "scribble": 2     # Artistic sketches
}
```

### âš¡ GPU Optimization Profiles:
```python
# ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð¾ GPU Ð¿Ð°Ð¼ÑÑ‚Ð¸
if gpu_memory >= 80:  # A100
    - memory_efficient: False
    - batch_size: 4-8
    - torch_compile: True

elif gpu_memory >= 24:  # RTX 4090
    - memory_efficient: True  
    - batch_size: 2
    - attention_slicing: True

else:  # <24GB
    - cpu_offload: True
    - batch_size: 1
    - all optimizations: True
```

## Conditioning Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹

### ðŸ–¼ï¸ Ð§ÐµÑ‚Ñ‹Ñ€Ðµ Ñ‚Ð¸Ð¿Ð° Conditioning:

#### 1. **Canny Edge Detection**
```python
class CannyConditioning:
    available_methods = [
        "opencv_canny",              # ÐšÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ¸Ð¹ OpenCV
        "structured_edge_detection", # Structured edges
        "adaptive_canny"             # Adaptive thresholding
    ]
```

#### 2. **Depth Estimation**  
```python
class DepthConditioning:
    available_methods = [
        "stroke_thickness_depth",    # ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚Ð¾Ð»Ñ‰Ð¸Ð½Ñ‹ Ð»Ð¸Ð½Ð¸Ð¹
        "distance_transform_depth",  # Distance transform
        "ai_depth_estimation"        # MiDaS AI Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    ]
```

#### 3. **Segmentation**
```python
class SegmentationConditioning:
    available_methods = [
        "radical_segmentation",      # ÐŸÐ¾ Ñ€Ð°Ð´Ð¸ÐºÐ°Ð»Ð°Ð¼ Kangxi
        "stroke_type_segmentation",  # ÐŸÐ¾ Ñ‚Ð¸Ð¿Ð°Ð¼ ÑˆÑ‚Ñ€Ð¸Ñ…Ð¾Ð²
        "ai_segmentation"            # SAM Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    ]
```

#### 4. **Scribble Generation**
```python
class ScribbleConditioning:
    available_methods = [
        "skeletonization_scribble",  # Zhang-Suen Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼
        "hand_drawn_simulation",     # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ Ñ€Ð¸ÑÐ¾Ð²Ð°Ð½Ð¸Ñ
        "style_aware_scribble"       # Ð¡Ñ‚Ð¸Ð»ÑŒ-Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ñ‹Ðµ Ð½Ð°Ð±Ñ€Ð¾ÑÐºÐ¸
    ]
```

## Prompt Engineering

### ðŸŽ¨ Style-Aware Prompt Building:

#### **Style Definitions** (`style_definitions.py`)
```python
styles = {
    "comic": StyleDefinition(
        base_template="A vibrant comic book style illustration of {meaning}, inspired by {character}",
        controlnet_weights={"canny": 0.9, "depth": 0.5, "segmentation": 0.7, "scribble": 0.3}
    ),
    "watercolor": StyleDefinition(
        base_template="A soft watercolor painting depicting {meaning}, with flowing brushstrokes",
        controlnet_weights={"canny": 0.4, "depth": 0.3, "segmentation": 0.3, "scribble": 0.8}
    )
}
```

#### **Intelligent Prompt Builder**
- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð²

## GPU ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ

### ðŸŽ® Intelligent GPU Management:

#### **Hardware Detection:**
```python
def _detect_gpu_info(self) -> Dict:
    device_props = torch.cuda.get_device_properties(0)
    return {
        "name": device_props.name,
        "total_memory_gb": device_props.total_memory / 1024**3,
        "temperature": get_gpu_temperature(),
        "power_usage": get_gpu_power()
    }
```

#### **Automatic Optimization:**
```python
def _determine_optimization_profile(self) -> OptimizationProfile:
    total_memory = self.gpu_info["total_memory_gb"]
    
    if total_memory >= 80:    # A100
        return UltraHighMemoryProfile()
    elif total_memory >= 24:  # RTX 4090  
        return HighMemoryProfile()
    else:                     # <24GB
        return MinimalMemoryProfile()
```

#### **Memory Monitoring:**
```python
@contextmanager
def memory_monitor(self, operation_name: str):
    memory_before = self.get_memory_usage()
    try:
        yield
    finally:
        memory_after = self.get_memory_usage()
        self.track_memory_usage(operation_name, memory_before, memory_after)
```

## API Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ

### ðŸŒ Writing Service API:

#### **AI Generation:**
```bash
curl -X POST http://localhost:8600/api/writing/generate-writing-image \
  -H "Content-Type: application/json" \
  -d '{
    "word": "å­¦ä¹ ",
    "translation": "study",
    "width": 1024,
    "height": 1024
  }'
```

#### **Response Format:**
```json
{
  "success": true,
  "generated_image_base64": "iVBORw0KGgoAAAANS...",
  "conditioning_images_base64": {
    "canny": {"opencv_canny": "base64..."},
    "depth": {"ai_depth_estimation": "base64..."}
  },
  "prompt_used": "A comic book style illustration...",
  "generation_metadata": {
    "generation_time_ms": 8500,
    "model_used": "stabilityai/stable-diffusion-xl-base-1.0",
    "controlnet_model": "union"
  }
}
```

#### **Health Checks:**
```bash
# Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°
GET /health

# AI Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°  
GET /health/detailed

# Ð“Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
GET /health/ready

# ÐŸÑ€Ð¾Ð³Ñ€ÐµÐ² AI
POST /health/warmup
```

## ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ

### ðŸ“Š Performance Monitoring:

#### **Generation Times by GPU:**
```
RTX 4090 (24GB):
â”œâ”€â”€ Cold start: ~15-30s (model loading)
â”œâ”€â”€ Warm generation: ~8-12s  
â””â”€â”€ Batch 2: ~14-18s

A100 (80GB):
â”œâ”€â”€ Cold start: ~10-20s
â”œâ”€â”€ Warm generation: ~6-8s
â””â”€â”€ Batch 4: ~18-24s
```

#### **Memory Usage:**
```
Models: ~6-8GB VRAM
â”œâ”€â”€ Stable Diffusion XL: ~4-5GB
â”œâ”€â”€ Union ControlNet: ~2-3GB  
â””â”€â”€ Generation overhead: +2-4GB peak
```

#### **Optimization Features:**
- **Lazy loading** - Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽÑ‚ÑÑ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ
- **Memory efficient attention** - XFormers optimization
- **GPU memory management** - Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ°

### ðŸ” Debugging:

#### **AI Status Dashboard:**
```bash
# Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
curl http://localhost:8600/api/writing/status

# GPU utilization  
curl http://localhost:8600/health/detailed | jq '.gpu_status'

# Generation statistics
curl http://localhost:8600/health/detailed | jq '.service_status.ai_status'
```

#### **Logging:**
```yaml
# AI-specific logging
logging:
  loggers:
    ai_models:
      level: "DEBUG" 
      include_model_loading: true
      include_memory_usage: true
    
    generation:
      level: "INFO"
      include_timing: true
      include_parameters: true
```
